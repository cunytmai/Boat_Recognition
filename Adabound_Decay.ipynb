{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os  \n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "from keras import initializers\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Flatten, Dropout, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.preprocessing import image\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "from keras import models\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "from keras.optimizers import SGD, Adam, Adagrad, RMSprop, Adadelta, Nadam\n",
    "from adabound import AdaBound\n",
    "from group_norm import GroupNormalization\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path, dirs, files = next(os.walk(r\"C:\\\\Users\\\\Tony\\\\Desktop\\\\Summer\\\\boat_classification\\\\data_aug2\"))\n",
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label = ['buoy',\n",
    " 'cruise ship',\n",
    " 'ferry boat',\n",
    " 'freight boat',\n",
    " 'gondola',\n",
    " 'inflatable boat',\n",
    " 'kayak',\n",
    " 'paper boat',\n",
    " 'sailboat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the augmented dataset\n",
    "i = 0\n",
    "\n",
    "X_data = []\n",
    "Y_data = []\n",
    "\n",
    "for boat in class_label:\n",
    "    files = glob.glob (r\"C:\\\\Users\\\\Tony\\\\Desktop\\\\Summer\\\\boat_classification\\data_aug2\\\\\" + str(boat) + \"/*.jpg\")\n",
    "    \n",
    "    for myFile in files:\n",
    "      img = Image.open(myFile)\n",
    "      #img.thumbnail((width, height), Image.ANTIALIAS) # resizes image in-place keeps ratio\n",
    "      img = img.resize((128,128), Image.ANTIALIAS) # resizes image without ratio\n",
    "      img = np.array(img)\n",
    "\n",
    "      if img.shape == (128, 128, 3):\n",
    "        # Add the numpy image to matrix with all data\n",
    "        X_data.append (img)\n",
    "        Y_data.append (i)\n",
    "        \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X_data)\n",
    "Y = np.array(Y_data)\n",
    "# Print shapes to see if they are correct\n",
    "# print(X.shape)\n",
    "# print(Y.shape)\n",
    "\n",
    "number_classes = [0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "for i in range(len(Y)):\n",
    "    if (Y[i] == 0):\n",
    "        number_classes[0] += 1\n",
    "    elif (Y[i] == 1):\n",
    "        number_classes[1] += 1\n",
    "    elif (Y[i] == 2):\n",
    "        number_classes[2] += 1\n",
    "    elif (Y[i] == 3):\n",
    "        number_classes[3] += 1\n",
    "    elif (Y[i] == 4):\n",
    "        number_classes[4] += 1\n",
    "    elif (Y[i] == 5):\n",
    "        number_classes[5] += 1\n",
    "    elif (Y[i] == 6):\n",
    "        number_classes[6] += 1\n",
    "    elif (Y[i] == 7):\n",
    "        number_classes[7] += 1\n",
    "    elif (Y[i] == 8):\n",
    "        number_classes[8] += 1\n",
    "    elif (Y[i] == 9):\n",
    "        number_classes[9] += 1\n",
    "\n",
    "print(\"Total Number of Samples: \", len(X))\n",
    "print(\"Number of Samples per Class after Augmentation:\")  \n",
    "\n",
    "for i in range(len(class_label)):\n",
    "     print(class_label[i], \":\", number_classes[i])\n",
    "\n",
    "objects = class_label\n",
    "y_pos = np.arange(len(objects))\n",
    "samples = number_classes\n",
    "\n",
    "plt.figure(figsize=[16,5])\n",
    "plt.bar(y_pos, samples, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects, size=15)\n",
    "plt.yticks(size=15)\n",
    "plt.title('Number of Samples per Class after Augmentation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the Data\n",
    "# y = (x - x.min) / (x.max - x.min)\n",
    "\n",
    "x_min = X.min(axis=(1, 2), keepdims=True)\n",
    "x_max = X.max(axis=(1, 2), keepdims=True)\n",
    "X = (X-x_min) / (x_max-x_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator()\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#         rotation_range=30,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "#         fill_mode='nearest',\n",
    "#         featurewise_center=True,\n",
    "#         featurewise_std_normalization=True,\n",
    "#         zca_whitening=True, \n",
    "#         zca_epsilon=1e-06\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat = to_categorical(Y_data, len(class_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(128, (5, 5), input_shape=(128, 128, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(GroupNormalization(groups=32, axis=-1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(GroupNormalization(groups=32, axis=-1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(GroupNormalization(groups=32, axis=-1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, kernel_initializer=initializers.glorot_uniform(seed=0), activation='relu'))\n",
    "model.add(Dense(9, kernel_initializer=initializers.glorot_uniform(seed=0), activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = AdaBound(lr=1e-03,\n",
    "                final_lr=0.1,\n",
    "                gamma=1e-03,\n",
    "                weight_decay=0.0,\n",
    "                amsbound=False), \n",
    "              loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valtest, y_train, y_valtest = train_test_split(X, y_cat, test_size=0.2)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_valtest, y_valtest, test_size=0.2)\n",
    "\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_val = X_val.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = ('Train', 'Validation', 'Test')\n",
    "y_pos = np.arange(len(objects))\n",
    "samples = []\n",
    "\n",
    "samples.append(len(X_train))\n",
    "samples.append(len(X_val))\n",
    "samples.append(len(X_test))\n",
    "\n",
    "print(\"Number of Samples Train: \", samples[0]) \n",
    "print(\"Number of Samples Validation: \", samples[1]) \n",
    "print(\"Number of Samples Test: \", samples[2]) \n",
    "\n",
    "plt.bar(y_pos, samples, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.title('Number of Samples')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen.fit(X_train)\n",
    "validation_datagen.fit(X_val)\n",
    "test_datagen.fit(X_test)\n",
    "\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=64)\n",
    "validation_generator = validation_datagen.flow(X_val, y_val, batch_size=64)\n",
    "test_generator = test_datagen.flow(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    initial_lrate = 1e-03\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    if (epoch == 10):\n",
    "        lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "        return lrate\n",
    "    elif (epoch == 20):\n",
    "        lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "        return lrate\n",
    "    elif (epoch == 25):\n",
    "        lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "        return lrate\n",
    "    elif (epoch == 30):\n",
    "        lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "        return lrate\n",
    "    else:\n",
    "        lrate = initial_lrate\n",
    "        return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "       self.losses = []\n",
    "       self.lr = []\n",
    " \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "       self.losses.append(logs.get('loss'))\n",
    "       self.lr.append(step_decay(len(self.losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "loss_history = LossHistory()\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "callbacks_list = [loss_history, lrate]\n",
    "\n",
    "history = model.fit_generator(\n",
    "    generator=train_generator, \n",
    "    steps_per_epoch=2*(len(X_train) // 64),\n",
    "    epochs=40, \n",
    "    validation_steps=10,\n",
    "    validation_data=validation_generator, \n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1 )\n",
    "\n",
    "model.save('model_Adabound_Decay_40_Epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "  \n",
    "# summarize history for accuracy\n",
    "plt.subplot(1, 2 ,1)\n",
    "plt.plot(np.arange(0, len(history.history['acc'])), acc, 'r', linewidth=3)\n",
    "plt.plot(np.arange(1, len(history.history['val_acc'])+1), val_acc, 'g', linewidth=3)\n",
    "plt.xticks(np.arange(0, 40+1, 2))\n",
    "plt.title('Training Accuracy vs. Validation Accuracy', fontsize = 15)\n",
    "plt.xlabel('Num of Epochs', fontsize=15)\n",
    "plt.ylabel('Accuracy', fontsize=15)\n",
    "plt.legend(['train acc', 'validation acc', 'train loss', 'validation loss'], loc='best', fontsize='large')\n",
    "  \n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(np.arange(1, len(history.history['loss'])+1), history.history['loss'], 'r', linewidth=3)\n",
    "plt.plot(np.arange(1, len(history.history['val_loss'])+1), history.history['val_loss'], 'g', linewidth=3)\n",
    "plt.xticks(np.arange(0, 40+1, 2))\n",
    "plt.title('Training Loss vs. Validation Loss', fontsize = 15)\n",
    "plt.xlabel('Num of Epochs', fontsize=15)\n",
    "plt.ylabel('Loss', fontsize=15)\n",
    "plt.legend(['train', 'validation'], loc='best', fontsize='large')\n",
    "  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "for i in range(len(acc)):\n",
    "    acc[i] = '{:.4}'.format(acc[i])\n",
    "    val_acc[i] = '{:.4}'.format(val_acc[i])\n",
    "    loss[i] = '{:.4}'.format(loss[i])\n",
    "    val_loss[i] = '{:.4}'.format(val_loss[i])\n",
    "    \n",
    "d = {'acc': acc, 'val_acc': val_acc, \n",
    "     'loss': loss, 'val_loss': val_loss}\n",
    "df = pd.DataFrame(data=d)\n",
    "print(df)\n",
    "\n",
    "# print(\"acc \\t\\t val_acc \\t loss \\t val_loss\")\n",
    "# print(\"------------------------------------------------------------------\")\n",
    "\n",
    "# for i in range(len(acc)):\n",
    "#     print('{:.4}'.format(acc[i]), \" \\t\", '{:.4}'.format(val_acc[i]), \"\\t\", \n",
    "#           '{:.4}'.format(loss[i]), \"\\t\", '{:.4}'.format(val_loss[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_img_batch, y_class_batch = test_generator[0] \n",
    "\n",
    "for i in range(1,len(test_generator)):\n",
    "    testX = test_generator[i][0]\n",
    "    testY = test_generator[i][1]\n",
    "    y_img_batch = np.concatenate((y_img_batch, testX))\n",
    "    y_class_batch = np.concatenate((y_class_batch, testY))\n",
    "\n",
    "y_pred = np.argmax(model.predict(y_img_batch),-1)\n",
    "y_true = np.argmax(y_class_batch,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(100):\n",
    "#     plt.imshow((y_img_batch[i]*255))\n",
    "#     actual_label = class_label[y_true[i]]\n",
    "#     predict_label = class_label[y_pred[i]]\n",
    "#     plt.title(\"Actual: \" + actual_label + \"| Prediction: \" + predict_label, fontsize = 15)\n",
    "#     plt.show()\n",
    "\n",
    "counterC = 0\n",
    "counterI = 0\n",
    "i = 10\n",
    "print('Incorrect Predictions: ')\n",
    "while counterI < 5:\n",
    "    actual_label = class_label[y_true[i]]\n",
    "    predict_label = class_label[y_pred[i]]\n",
    "    if (actual_label != predict_label):\n",
    "        plt.imshow((y_img_batch[i]*255))\n",
    "        plt.title(\"Actual: \" + actual_label + \"| Prediction: \" + predict_label, fontsize = 15)\n",
    "        plt.show()\n",
    "        counterI+=1\n",
    "        i+=1\n",
    "    else:\n",
    "        i+=1\n",
    "     \n",
    "print('Correct Predictions: ')\n",
    "while counterC < 5:\n",
    "    actual_label = class_label[y_true[i]]\n",
    "    predict_label = class_label[y_pred[i]]\n",
    "    if (actual_label == predict_label):\n",
    "        plt.imshow((y_img_batch[i]*255))\n",
    "        plt.title(\"Actual: \" + actual_label + \"| Prediction: \" + predict_label, fontsize = 15)\n",
    "        plt.show()\n",
    "        counterC+=1\n",
    "        i+=1\n",
    "    else:\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred) \n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.title('Prediction of Boats', fontsize = 25)\n",
    "sns.heatmap(cmn, annot=True, fmt=\".2f\", linewidths=.5, cmap=\"Blues\", annot_kws={\"size\": 25})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=class_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "\n",
    "n_classes = len(class_label)\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(y_test)\n",
    "y_true = lb.transform(y_true)\n",
    "y_pred = lb.transform(y_pred)\n",
    "\n",
    "lw = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        \n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    \n",
    "#     # Plot of a ROC curve for a specific class\n",
    "#     for i in range(n_classes):\n",
    "#         plt.figure(figsize=(15,15))\n",
    "#         plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
    "#         plt.plot([0, 1], [0, 1], 'k--')\n",
    "#         plt.xlim([0.0, 1.0])\n",
    "#         plt.ylim([0.0, 1.05])\n",
    "#         plt.xlabel('False Positive Rate')\n",
    "#         plt.ylabel('True Positive Rate')\n",
    "#         plt.title('Receiver operating characteristic example')\n",
    "#         plt.legend(loc=\"lower right\")\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    plt.figure(figsize=(21,21))\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=lw)\n",
    "\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=lw)\n",
    "\n",
    "    colors = cycle(['navy', 'turquoise', 'darkorange', 'cornflowerblue', 'teal', 'red', 'green', 'brown', 'purple'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "            label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize = 25)\n",
    "    plt.ylabel('True Positive Rate', fontsize = 25)\n",
    "    plt.title('ROC and AUC Curve', fontsize = 25)\n",
    "    plt.legend(loc=\"lower right\",fontsize='xx-large')\n",
    "    plt.show()\n",
    "        \n",
    "    return roc_auc_score(y_test, y_pred, average=average)\n",
    "\n",
    "print(\"ROC_AUC_Score:\", multiclass_roc_auc_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "    \n",
    "# For each class\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "for i in range(n_classes):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_true[:, i],\n",
    "                                                        y_pred[:, i])\n",
    "    average_precision[i] = average_precision_score(y_true[:, i], y_pred[:, i])\n",
    "\n",
    "# A \"micro-average\": quantifying score on all classes jointly\n",
    "precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(y_true.ravel(),\n",
    "    y_pred.ravel())\n",
    "average_precision[\"micro\"] = average_precision_score(y_true, y_pred,\n",
    "                                                     average=\"micro\")\n",
    "print('Average precision score, micro-averaged over all classes: {0:0.4f}'\n",
    "      .format(average_precision[\"micro\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.step(recall['micro'], precision['micro'], color='black', alpha=1.0,\n",
    "         where='post')\n",
    "plt.fill_between(recall[\"micro\"], precision[\"micro\"], alpha=0.2, color='blue')#,\n",
    "                 #**step_kwargs)\n",
    "\n",
    "plt.xlabel('Recall', fontsize = 15)\n",
    "plt.ylabel('Precision', fontsize = 15)\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title(\n",
    "    'Average precision score, micro-averaged over all classes: AP={0:0.4f}'\n",
    "    .format(average_precision[\"micro\"]), fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup plot details\n",
    "colors = cycle(['navy', 'turquoise', 'darkorange', 'cornflowerblue', 'teal', 'red', 'green', 'brown', 'purple'])\n",
    "\n",
    "plt.figure(figsize=(21, 21))\n",
    "f_scores = np.linspace(0.2, 0.8, num=4)\n",
    "lines = []\n",
    "labels = []\n",
    "for f_score in f_scores:\n",
    "    x = np.linspace(0.01, 1)\n",
    "    y = f_score * x / (2 * x - f_score)\n",
    "    l, = plt.plot(x[y >= 0], y[y >= 0], color='gray', alpha=0.2)\n",
    "    plt.annotate('f1={0:0.1f}'.format(f_score), xy=(0.9, y[45] + 0.02))\n",
    "\n",
    "lines.append(l)\n",
    "labels.append('iso-f1 curves')\n",
    "l, = plt.plot(recall[\"micro\"], precision[\"micro\"], color='gold', lw=lw)\n",
    "lines.append(l)\n",
    "labels.append('micro-average Precision-recall (area = {0:0.2f})'\n",
    "              ''.format(average_precision[\"micro\"]))\n",
    "\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    l, = plt.plot(recall[i], precision[i], color=color, lw=2)\n",
    "    lines.append(l)\n",
    "    labels.append('Precision-recall for class:{0} (area = {1:0.2f})'\n",
    "                  ''.format(i, average_precision[i]))\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.subplots_adjust(bottom=0.25)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall', fontsize = 25)\n",
    "plt.ylabel('Precision', fontsize = 25)\n",
    "plt.title('Precision-Recall Curve', fontsize = 25)\n",
    "plt.legend(lines, labels, loc='lower left', fontsize='xx-large')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
